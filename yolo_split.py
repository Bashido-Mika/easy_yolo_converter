#!/usr/bin/env python3
"""
YOLO Dataset Splitter

YOLOå½¢å¼ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’train/val/testã«åˆ†å‰²ã—ã¾ã™ã€‚
scikit-learnã®train_test_splitã‚’ä½¿ç”¨ã—ã¦åŠ¹ç‡çš„ã«åˆ†å‰²ã—ã€
Ultralyticsç”¨ã®data.yamlã‚’è‡ªå‹•ç”Ÿæˆã—ã¾ã™ã€‚

Reference: https://docs.ultralytics.com/ja/datasets/segment/coco128-seg/#dataset-yaml
"""

import argparse
import shutil
import yaml
from pathlib import Path
from typing import List, Tuple, Dict, Set, Optional
from dataclasses import dataclass
from tqdm import tqdm
from sklearn.model_selection import train_test_split


# å®šæ•°
DEFAULT_IMAGE_EXTENSIONS = ['.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG']
DEFAULT_INPUT_DIR = 'Yolo_crop'
DEFAULT_OUTPUT_DIR = 'Yolo_split'
DEFAULT_TRAIN_RATIO = 0.7
DEFAULT_VAL_RATIO = 0.2
DEFAULT_TEST_RATIO = 0.1
DEFAULT_RANDOM_SEED = 42


@dataclass
class ImageLabelPair:
    """ç”»åƒã¨ãƒ©ãƒ™ãƒ«ã®ãƒšã‚¢"""
    image_path: Path
    label_path: Path
    name: str


@dataclass
class SplitConfig:
    """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåˆ†å‰²ã®è¨­å®š"""
    input_dir: Path
    output_dir: Path
    train_ratio: float
    val_ratio: float
    test_ratio: float
    random_seed: int
    class_names: Optional[List[str]] = None
    image_extensions: List[str] = None
    
    def __post_init__(self):
        if self.image_extensions is None:
            self.image_extensions = DEFAULT_IMAGE_EXTENSIONS
    
    def validate(self) -> bool:
        """è¨­å®šã®å¦¥å½“æ€§ã‚’ãƒã‚§ãƒƒã‚¯"""
        total_ratio = self.train_ratio + self.val_ratio + self.test_ratio
        if abs(total_ratio - 1.0) > 0.001:
            tqdm.write(f"âš ï¸ è­¦å‘Š: åˆ†å‰²æ¯”ç‡ã®åˆè¨ˆãŒ {total_ratio:.3f} ã§ã™ï¼ˆ1.0ã§ã‚ã‚‹ã¹ãï¼‰")
            return False
        return True


class YoloDatasetSplitter:
    """YOLOå½¢å¼ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’train/val/testã«åˆ†å‰²ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, config: SplitConfig):
        """
        åˆæœŸåŒ–
        
        Args:
            config: åˆ†å‰²è¨­å®š
        """
        self.config = config
        self.pairs: List[ImageLabelPair] = []
        self.train_pairs: List[ImageLabelPair] = []
        self.val_pairs: List[ImageLabelPair] = []
        self.test_pairs: List[ImageLabelPair] = []
        self.class_ids: Set[int] = set()
    
    def find_image_label_pairs(self) -> Tuple[List[str], List[str]]:
        """
        ç”»åƒã¨ãƒ©ãƒ™ãƒ«ã®ãƒšã‚¢ã‚’æ¢ã™
        
        Returns:
            (ãƒ©ãƒ™ãƒ«ãŒãªã„ç”»åƒãƒªã‚¹ãƒˆ, ç”»åƒãŒãªã„ãƒ©ãƒ™ãƒ«ãƒªã‚¹ãƒˆ)
        """
        input_dir = self.config.input_dir
        
        # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’åé›†
        image_files = []
        for ext in self.config.image_extensions:
            image_files.extend(input_dir.glob(f"*{ext}"))
        
        # ç”»åƒã¨ãƒ©ãƒ™ãƒ«ã®ãƒšã‚¢ã‚’ä½œæˆ
        missing_labels = []
        for img_file in image_files:
            label_file = img_file.with_suffix('.txt')
            if label_file.exists():
                self.pairs.append(ImageLabelPair(
                    image_path=img_file,
                    label_path=label_file,
                    name=img_file.stem
                ))
            else:
                missing_labels.append(img_file.name)
        
        # ãƒ©ãƒ™ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿å­˜åœ¨ã™ã‚‹ã‚±ãƒ¼ã‚¹ã‚’ãƒã‚§ãƒƒã‚¯
        all_labels = list(input_dir.glob("*.txt"))
        missing_images = []
        for label_file in all_labels:
            has_image = any(
                label_file.with_suffix(ext).exists() 
                for ext in self.config.image_extensions
            )
            if not has_image:
                missing_images.append(label_file.name)
        
        return missing_labels, missing_images
    
    def split_dataset(self) -> None:
        """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’train/val/testã«åˆ†å‰²"""
        if not self.pairs:
            return
        
        # ã¾ãštrain+valã¨testã«åˆ†å‰²
        if self.config.test_ratio > 0:
            train_val_pairs, self.test_pairs = train_test_split(
                self.pairs,
                test_size=self.config.test_ratio,
                random_state=self.config.random_seed
            )
        else:
            train_val_pairs = self.pairs
            self.test_pairs = []
        
        # train+valã‚’trainã¨valã«åˆ†å‰²
        if self.config.val_ratio > 0 and train_val_pairs:
            val_ratio_adjusted = self.config.val_ratio / (
                self.config.train_ratio + self.config.val_ratio
            )
            self.train_pairs, self.val_pairs = train_test_split(
                train_val_pairs,
                test_size=val_ratio_adjusted,
                random_state=self.config.random_seed
            )
        else:
            self.train_pairs = train_val_pairs
            self.val_pairs = []
    
    def copy_pairs(
        self, 
        pairs: List[ImageLabelPair], 
        split_name: str
    ) -> int:
        """
        ç”»åƒã¨ãƒ©ãƒ™ãƒ«ã®ãƒšã‚¢ã‚’ã‚³ãƒ”ãƒ¼
        
        Args:
            pairs: ã‚³ãƒ”ãƒ¼ã™ã‚‹ãƒšã‚¢ã®ãƒªã‚¹ãƒˆ
            split_name: åˆ†å‰²åï¼ˆtrain/val/testï¼‰
        
        Returns:
            ã‚³ãƒ”ãƒ¼ã—ãŸæ•°
        """
        if not pairs:
            return 0
        
        output_dir = self.config.output_dir
        images_dir = output_dir / split_name / "images"
        labels_dir = output_dir / split_name / "labels"
        images_dir.mkdir(parents=True, exist_ok=True)
        labels_dir.mkdir(parents=True, exist_ok=True)
        
        for pair in tqdm(pairs, desc=f"{split_name:5s}", ncols=100):
            shutil.copy2(pair.image_path, images_dir / pair.image_path.name)
            shutil.copy2(pair.label_path, labels_dir / pair.label_path.name)
        
        return len(pairs)
    
    def extract_class_ids(self) -> None:
        """ã™ã¹ã¦ã®ãƒ©ãƒ™ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚¯ãƒ©ã‚¹IDã‚’æŠ½å‡º"""
        all_pairs = self.train_pairs + self.val_pairs + self.test_pairs
        
        for pair in all_pairs:
            try:
                with open(pair.label_path, 'r') as f:
                    for line in f:
                        line = line.strip()
                        if line:
                            parts = line.split()
                            if len(parts) >= 5:
                                class_id = int(parts[0])
                                self.class_ids.add(class_id)
            except Exception as e:
                tqdm.write(f"âš ï¸ ãƒ©ãƒ™ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {pair.label_path.name} - {e}")
    
    def create_data_yaml(self) -> Optional[Path]:
        """
        Ultralyticsç”¨ã®data.yamlãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        
        Reference: https://docs.ultralytics.com/ja/datasets/segment/coco128-seg/#dataset-yaml
        
        Returns:
            ä½œæˆã—ãŸdata.yamlã®ãƒ‘ã‚¹ï¼ˆå¤±æ•—æ™‚ã¯Noneï¼‰
        """
        if not self.class_ids:
            tqdm.write("âš ï¸ è­¦å‘Š: ã‚¯ãƒ©ã‚¹IDãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚data.yamlã®ç”Ÿæˆã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            return None
        
        yaml_path = self.config.output_dir / 'data.yaml'
        sorted_class_ids = sorted(self.class_ids)
        
        # ã‚¯ãƒ©ã‚¹åã®è¾æ›¸ã‚’ä½œæˆ
        if self.config.class_names and len(self.config.class_names) == len(sorted_class_ids):
            names_dict = {cls_id: name for cls_id, name in zip(sorted_class_ids, self.config.class_names)}
        else:
            if self.config.class_names:
                tqdm.write(f"âš ï¸ è­¦å‘Š: ã‚¯ãƒ©ã‚¹åã®æ•°({len(self.config.class_names)})ã¨ã‚¯ãƒ©ã‚¹IDã®æ•°({len(sorted_class_ids)})ãŒä¸€è‡´ã—ã¾ã›ã‚“")
                tqdm.write(f"   è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸã‚¯ãƒ©ã‚¹åã‚’ä½¿ç”¨ã—ã¾ã™")
            names_dict = {cls_id: f'class{cls_id}' for cls_id in sorted_class_ids}
        
        # Ultralyticså½¢å¼ã®data.yamlã‚’æ§‹ç¯‰
        # Reference: https://docs.ultralytics.com/ja/datasets/segment/coco128-seg/#dataset-yaml
        data = {
            'path': str(self.config.output_dir.absolute()).replace('\\', '/'),
            'train': 'train/images',
            'val': 'val/images',
            'names': names_dict  # è¾æ›¸å½¢å¼ï¼ˆ0: class_nameï¼‰
        }
        
        # testã‚»ãƒƒãƒˆãŒã‚ã‚‹å ´åˆã¯è¿½åŠ 
        if self.test_pairs:
            data['test'] = 'test/images'
        
        # YAMLãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿
        with open(yaml_path, 'w', encoding='utf-8') as f:
            yaml.dump(data, f, default_flow_style=False, sort_keys=False, allow_unicode=True)
        
        return yaml_path
    
    def print_statistics(self) -> None:
        """çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º"""
        total = len(self.pairs)
        if total == 0:
            return
        
        tqdm.write("\nåˆ†å‰²çµæœ:")
        tqdm.write(f"  Train: {len(self.train_pairs):4d}çµ„ ({len(self.train_pairs)/total*100:5.1f}%)")
        tqdm.write(f"  Val:   {len(self.val_pairs):4d}çµ„ ({len(self.val_pairs)/total*100:5.1f}%)")
        tqdm.write(f"  Test:  {len(self.test_pairs):4d}çµ„ ({len(self.test_pairs)/total*100:5.1f}%)")
        tqdm.write(f"  åˆè¨ˆ:  {total:4d}çµ„")
    
    def print_output_summary(self) -> None:
        """å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®æ¦‚è¦ã‚’è¡¨ç¤º"""
        tqdm.write("\nå‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ç¢ºèª:")
        for split_name in ["train", "val", "test"]:
            images_dir = self.config.output_dir / split_name / "images"
            labels_dir = self.config.output_dir / split_name / "labels"
            
            if images_dir.exists():
                image_count = len(list(images_dir.glob("*")))
                label_count = len(list(labels_dir.glob("*.txt")))
                tqdm.write(f"  ğŸ“ {split_name:5s}: ç”»åƒ={image_count:4d}æš, ãƒ©ãƒ™ãƒ«={label_count:4d}å€‹")
    
    def run(self) -> bool:
        """
        ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåˆ†å‰²ã®å®Ÿè¡Œ
        
        Returns:
            æˆåŠŸã—ãŸå ´åˆTrueã€å¤±æ•—ã—ãŸå ´åˆFalse
        """
        # è¨­å®šã®æ¤œè¨¼
        self.config.validate()
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼è¡¨ç¤º
        tqdm.write("=" * 60)
        tqdm.write("YOLO Dataset Splitter")
        tqdm.write("=" * 60)
        tqdm.write(f"å…¥åŠ›: {self.config.input_dir}")
        tqdm.write(f"å‡ºåŠ›: {self.config.output_dir}")
        tqdm.write(f"åˆ†å‰²æ¯”ç‡: Train={self.config.train_ratio}, Val={self.config.val_ratio}, Test={self.config.test_ratio}")
        tqdm.write(f"ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰: {self.config.random_seed}")
        tqdm.write("-" * 60)
        
        # ãƒšã‚¢ã®æ¤œç´¢
        tqdm.write("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç¢ºèªã—ã¦ã„ã¾ã™...")
        missing_labels, missing_images = self.find_image_label_pairs()
        
        # çµæœè¡¨ç¤º
        tqdm.write(f"\nğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±:")
        tqdm.write(f"   æ­£å¸¸ãªãƒšã‚¢: {len(self.pairs)}çµ„")
        
        if missing_labels:
            tqdm.write(f"   âš ï¸ ãƒ©ãƒ™ãƒ«ãŒãªã„ç”»åƒ: {len(missing_labels)}å€‹")
            for name in missing_labels[:5]:
                tqdm.write(f"      - {name}")
            if len(missing_labels) > 5:
                tqdm.write(f"      ï¼ˆä»– {len(missing_labels) - 5}å€‹ï¼‰")
        
        if missing_images:
            tqdm.write(f"   âš ï¸ ç”»åƒãŒãªã„ãƒ©ãƒ™ãƒ«: {len(missing_images)}å€‹")
            for name in missing_images[:5]:
                tqdm.write(f"      - {name}")
            if len(missing_images) > 5:
                tqdm.write(f"      ï¼ˆä»– {len(missing_images) - 5}å€‹ï¼‰")
        
        if not self.pairs:
            tqdm.write("\nâŒ ã‚¨ãƒ©ãƒ¼: æœ‰åŠ¹ãªç”»åƒã¨ãƒ©ãƒ™ãƒ«ã®ãƒšã‚¢ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return False
        
        tqdm.write("-" * 60)
        
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåˆ†å‰²
        tqdm.write("\nãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’åˆ†å‰²ã—ã¦ã„ã¾ã™...")
        self.split_dataset()
        self.print_statistics()
        tqdm.write("-" * 60)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚³ãƒ”ãƒ¼
        tqdm.write(f"\nãƒ•ã‚¡ã‚¤ãƒ«ã‚’ {self.config.output_dir} ã«ã‚³ãƒ”ãƒ¼ã—ã¦ã„ã¾ã™...\n")
        self.copy_pairs(self.train_pairs, "train")
        self.copy_pairs(self.val_pairs, "val")
        self.copy_pairs(self.test_pairs, "test")
        
        tqdm.write("\n" + "-" * 60)
        
        # å‡ºåŠ›ç¢ºèª
        self.print_output_summary()
        tqdm.write("\n" + "-" * 60)
        
        # data.yamlç”Ÿæˆ
        tqdm.write("\ndata.yaml ã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™...")
        self.extract_class_ids()
        
        if self.class_ids:
            tqdm.write(f"   æ¤œå‡ºã•ã‚ŒãŸã‚¯ãƒ©ã‚¹ID: {sorted(self.class_ids)}")
            if self.config.class_names:
                tqdm.write(f"   ä½¿ç”¨ã™ã‚‹ã‚¯ãƒ©ã‚¹å: {self.config.class_names}")
            
            yaml_path = self.create_data_yaml()
            if yaml_path:
                tqdm.write(f"   âœ… data.yaml ã‚’ä½œæˆã—ã¾ã—ãŸ: {yaml_path}")
                
                # data.yamlã®å†…å®¹ã‚’è¡¨ç¤º
                tqdm.write("\nğŸ“„ data.yaml ã®å†…å®¹:")
                with open(yaml_path, 'r', encoding='utf-8') as f:
                    for line in f:
                        tqdm.write(f"   {line.rstrip()}")
        
        # å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        tqdm.write("\n" + "=" * 60)
        tqdm.write("âœ… å®Œäº†ï¼")
        tqdm.write(f"   å‡ºåŠ›å…ˆ: {self.config.output_dir}")
        if self.class_ids:
            tqdm.write(f"   data.yaml: {self.config.output_dir / 'data.yaml'}")
        tqdm.write("=" * 60)
        
        return True


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    parser = argparse.ArgumentParser(
        description='YOLOå½¢å¼ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’train/val/testã«åˆ†å‰²',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã§å®Ÿè¡Œï¼ˆdata.yamlã‚‚è‡ªå‹•ç”Ÿæˆï¼‰
  python yolo_split.py
  
  # å…¥åŠ›ã¨å‡ºåŠ›ã‚’æŒ‡å®š
  python yolo_split.py -i ./yolo_dataset -o ./yolo_split
  
  # åˆ†å‰²æ¯”ç‡ã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºï¼ˆ80/10/10ï¼‰
  python yolo_split.py -i ./yolo_dataset -o ./yolo_split --train 0.8 --val 0.1 --test 0.1
  
  # testãªã—ï¼ˆtrain/valã®ã¿ï¼‰
  python yolo_split.py -i ./yolo_dataset -o ./yolo_split --train 0.8 --val 0.2 --test 0
  
  # ã‚¯ãƒ©ã‚¹åã‚’æŒ‡å®šã—ã¦data.yamlã‚’ç”Ÿæˆ
  python yolo_split.py -i ./yolo_dataset -o ./yolo_split --class-names pod flower leaf
  
  # ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰ã‚’æŒ‡å®š
  python yolo_split.py -i ./yolo_dataset -o ./yolo_split --seed 123

å‚è€ƒ:
  Ultralytics YOLO Dataset Format: https://docs.ultralytics.com/ja/datasets/segment/coco128-seg/#dataset-yaml
        """
    )
    
    parser.add_argument(
        '-i', '--input',
        type=Path,
        default=Path(DEFAULT_INPUT_DIR),
        help=f'å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆYOLOå½¢å¼ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼‰ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {DEFAULT_INPUT_DIR})'
    )
    
    parser.add_argument(
        '-o', '--output',
        type=Path,
        default=Path(DEFAULT_OUTPUT_DIR),
        help=f'å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {DEFAULT_OUTPUT_DIR})'
    )
    
    parser.add_argument(
        '--train',
        type=float,
        default=DEFAULT_TRAIN_RATIO,
        help=f'ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚»ãƒƒãƒˆã®æ¯”ç‡ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {DEFAULT_TRAIN_RATIO})'
    )
    
    parser.add_argument(
        '--val',
        type=float,
        default=DEFAULT_VAL_RATIO,
        help=f'æ¤œè¨¼ã‚»ãƒƒãƒˆã®æ¯”ç‡ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {DEFAULT_VAL_RATIO})'
    )
    
    parser.add_argument(
        '--test',
        type=float,
        default=DEFAULT_TEST_RATIO,
        help=f'ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã®æ¯”ç‡ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {DEFAULT_TEST_RATIO})'
    )
    
    parser.add_argument(
        '--seed',
        type=int,
        default=DEFAULT_RANDOM_SEED,
        help=f'ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰ï¼ˆå†ç¾æ€§ã®ãŸã‚ï¼‰ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {DEFAULT_RANDOM_SEED})'
    )
    
    parser.add_argument(
        '--class-names',
        type=str,
        nargs='+',
        default=None,
        help='ã‚¯ãƒ©ã‚¹åã®ãƒªã‚¹ãƒˆï¼ˆä¾‹: --class-names pod flower leafï¼‰çœç•¥æ™‚ã¯è‡ªå‹•ç”Ÿæˆ'
    )
    
    args = parser.parse_args()
    
    # å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ç¢ºèª
    if not args.input.exists():
        tqdm.write(f"âŒ ã‚¨ãƒ©ãƒ¼: å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“: {args.input}")
        return
    
    # è¨­å®šã‚’ä½œæˆ
    config = SplitConfig(
        input_dir=args.input,
        output_dir=args.output,
        train_ratio=args.train,
        val_ratio=args.val,
        test_ratio=args.test,
        random_seed=args.seed,
        class_names=args.class_names
    )
    
    # ã‚¹ãƒ—ãƒªãƒƒã‚¿ãƒ¼ã‚’å®Ÿè¡Œ
    splitter = YoloDatasetSplitter(config)
    splitter.run()


if __name__ == '__main__':
    main()
